{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "FCLB_TFOD.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIV8j7m1jXDZ"
      },
      "source": [
        "#import neccessary python modules and libraries\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "import uuid\n",
        "import tarfile"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78s0FVL4mMg5"
      },
      "source": [
        "# Adding Classes for Path Setup and Project Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My2TVbX8lvMq"
      },
      "source": [
        "class Setup_Path: \n",
        "\n",
        "    IMAGES_PATHS = [\"original_images\", \"preprocessed_images\", \"labeled_images\"]\n",
        "    LABELS = [\"Fresh_Ripe\", \"Fresh_Unripe\", \"Rotten_Ripe\", \"Rotten_Unripe\"]\n",
        "    MODELS = [\"eval\", \"export\", \"tjsexport\", \"train\"]\n",
        "    EXPORT = [\"checkpoint\", \"saved_model\"]\n",
        "    SAVED_MODEL = [\"assets\", \"variables\"]\n",
        "    #API_MODEL = Pretrained_Model(\"my_ssd_mobnet\", \"ssd_mobilenet_v2_320x320_coco17_tpu-8\", \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\", \"generate_tfrecord.py\", \"label_map.pbtxt\")\n",
        "    SUB_PATHS = [\"Train\", \"Test\", \"Validation\"]\n",
        "    SUB_DIRS = [\"anotations\",\"models\", \"images\", \"datasets\", \"pretrained_model\", \"detection_images\"]\n",
        "    \n",
        "    def __init__(self, custom_name, pretrained_model_name, model_url, tfrecord_name, map_name):\n",
        "        self.custom_name = custom_name\n",
        "        self.pretrained_name = pretrained_model_name\n",
        "        self.model_url = model_url,\n",
        "        self.tfrecord_name = tfrecord_name\n",
        "        self.map_name = map_name\n",
        "        MAIN_PATHS = [\"workspace\", \"tensorflow_api_model\", \"protobuf\", \"tfrecord_generator\", \"train_model\", \"deployment\"]\n",
        "        self.main_paths = MAIN_PATHS\n",
        "\n",
        "    def get_main_paths(self):\n",
        "        paths = {\n",
        "            \"WORKSPACE_PATH\": \"workspace\",\n",
        "            \"TENSORFLOW_API_MODEL_PATH\": \"TFOD_API\",\n",
        "            \"PROTOBUF_PATH\": \"protobuf\",\n",
        "            \"ANOTATIONS_PATH\": os.path.join(\"workspace\",\"anotations\"),\n",
        "            \"IMAGES_PATH\": os.path.join(\"workspace\",\"images\"),\n",
        "            \"DATASETS_PATH\": os.path.join(\"workspace\",\"datasets\"),\n",
        "            \"MODELS_PATH\": os.path.join(\"workspace\",\"models\"),\n",
        "            \"PRETRAINED_MODEL_PATH\": os.path.join(\"workspace\",\"pretrained_model\"),\n",
        "            \"OUTPUT_PATH\": os.path.join(\"workspace\", \"anotations\", \"export\"),\n",
        "            \"TFJS_PATH\": os.path.join(\"workspace\", \"anotations\", \"tjsexport\"),\n",
        "            \"DEPLOYMENT_PATH\":os.path.join(\"workspace\"),#for opencv, testing for computer vision\n",
        "            \"CHECKPOINT_PATH\": os.path.join(\"workspace\", self.custom_name),\n",
        "            \n",
        "        }\n",
        "\n",
        "        return paths\n",
        "\n",
        "    def set_main_paths(self):\n",
        "        for path in self.get_main_paths().values():\n",
        "            if not os.path.exists(path):\n",
        "                os.makedirs(path)\n",
        "\n",
        "    def get_image_paths(self):\n",
        "        path = {\n",
        "            \"ORIGINAL_IMAGES_PATH\" : [\"workspace\\datasets\\original_images\\Fresh_Ripe\", \"workspace\\datasets\\original_images\\Fresh_Unripe\", \"workspace\\datasets\\original_images\\Rotten_Ripe\", \"workspace\\datasets\\original_images\\Rotten_Unripe\"],\n",
        "            \"PREPROCESSED_IMAGES_PATH\" : [\"workspace\\datasets\\preprocessed_images\\Fresh_Ripe\", \"workspace\\datasets\\preprocessed_images\\Fresh_Unripe\", \"workspace\\datasets\\preprocessed_images\\Rotten_Ripe\", \"workspace\\datasets\\preprocessed_images\\Rotten_Unripe\"],\n",
        "        }\n",
        "\n",
        "        return path\n",
        "\n",
        "    def set_image_paths(self):\n",
        "        for path in self.get_image_paths().values():\n",
        "            for label in path:\n",
        "                if not os.path.exists(label):\n",
        "                    os.makedirs(label)\n",
        "\n",
        "    def getFiles(self):\n",
        "        files = {\n",
        "            'PIPELINE_CONFIG':os.path.join(self.get_paths()['MODELS_PATH'], self.custom_name, 'pipeline.config'),\n",
        "            'TF_RECORD_SCRIPT':os.path.join(self.get_paths()['TFRECORD_GENERATOR_PATH'], self.tfrecord_name),\n",
        "            'LABEL_MAP':os.path.join(self.get_paths()['ANOTATIONS_PATH'], self.map_name),\n",
        "        }\n",
        "        return files\n",
        "\n",
        "    def get_dataset_paths(self):\n",
        "        path = {\n",
        "            'ORIGINAL_IMAGES_PATH': os.path.join(self.get_main_paths()['DATASETS_PATH'], self.IMAGES_PATHS[0]),\n",
        "            'PREPROCESSED_IMAGES_PATH': os.path.join(self.get_main_paths()['DATASETS_PATH'], self.IMAGES_PATHS[1]),\n",
        "            'LABELED_IMAGES_PATH': os.path.join(self.get_main_paths()['DATASETS_PATH'], self.IMAGES_PATHS[2]),\n",
        "        }\n",
        "        return path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlWNaTvfl6ZI"
      },
      "source": [
        "path = Setup_Path(\"my_ssd_mobnet\", \"ssd_mobilenet_v2_320x320_coco17_tpu-8\", \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\", \"generate_tfrecord.py\", \"label_map.pbtxt\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lD26arHmG7-"
      },
      "source": [
        "class FCLB_Datasets:\n",
        "    #class' constructor\n",
        "    def __init__(self, setup):\n",
        "        self.setup = setup\n",
        "    \n",
        "    #acquiring uncategorized dataset\n",
        "    def get_original_dataset(self, num1, num2, label):\n",
        "        images_path = self.setup.get_dataset_paths()['PREPROCESSED_IMAGES_PATH']\n",
        "        path = os.path.join(images_path, label)\n",
        "\n",
        "        files = [\"{}\".format(i) for i in os.listdir(path)[num1:num2]]\n",
        "\n",
        "        return files\n",
        "\n",
        "    def copy_image_file(self, subPath, num1, num2):\n",
        "\n",
        "        for label in self.setup.LABELS:\n",
        "            for file in self.get_original_dataset(num1, num2, label):\n",
        "                dst = os.path.join(self.setup.get_main_paths()['IMAGES_PATH'], subPath, label, file)\n",
        "                src = os.path.join(self.setup.get_dataset_paths()['PREPROCESSED_IMAGES_PATH'], label, file)\n",
        "                shutil.copyfile(src, dst)\n",
        "\n",
        "    #define a function that returns path of datasets sub_directories which is a labels\n",
        "    def getDir(self,path):\n",
        "        return self.setup.get_dataset_paths()[path]\n",
        "\n",
        "    #I call it segment function, wala na koy mahunahunaan\n",
        "    def segment(self):\n",
        "        original_dir = self.getDir('ORIGINAL_IMAGES_PATH')\n",
        "        target_dir = self.getDir('PREPROCESSED_IMAGES_PATH')\n",
        "        sub_dirs = self.getSubDirectories(original_dir)\n",
        "\n",
        "        for sub_dir in sub_dirs:\n",
        "            original = os.path.join(original_dir, sub_dir)\n",
        "            target = os.path.join(target_dir, sub_dir)\n",
        "            for img in os.listdir(original):\n",
        "                self.segmentation(original, target, img)\n",
        "    #this function gets a list of sub directories, ex. fresh unripe, rotten unripe\n",
        "    def getSubDirectories(self, dir):\n",
        "        return os.listdir(dir)  \n",
        "\n",
        "    #this function used to segment an image file, it actually resize image, add contrast and lightness\n",
        "    #and save it to the target directory\n",
        "    #the purpose of uuid module is to give unique id or name to an image file\n",
        "    def segmentation(self, base_dir, target_dir, fname):\n",
        "        image = Image.open(os.path.join(base_dir, fname))\n",
        "        size = (400,400)\n",
        "        image.thumbnail(size)\n",
        "        image.save(os.path.join(target_dir, '{}.jpg'.format(uuid.uuid1())))\n",
        "\n",
        "        contrast = ImageEnhance.Contrast(image)\n",
        "        contrast.enhance(1.8).save(os.path.join(target_dir, '{}.jpg'.format(uuid.uuid1())))\n",
        "\n",
        "        brightness = ImageEnhance.Brightness(image)\n",
        "        brightness.enhance(1.2).save(os.path.join(target_dir, '{}.jpg'.format(uuid.uuid1())))\n",
        "\n",
        "    #compressed file for github upload\n",
        "    def compressed(self):\n",
        "        path = self.getDir('PREPROCESSED_IMAGES_PATH')\n",
        "        sub_paths = self.getSubDirectories(path)\n",
        "        ARCHIVE_PATH = os.path.join(path, 'preprocessed_images.tar.gz')\n",
        "        tar = tarfile.open(ARCHIVE_PATH, \"w:gz\")\n",
        "        for sub_path in sub_paths:\n",
        "            dir = os.path.join(path, sub_path)\n",
        "            tar.add(dir)\n",
        "        tar.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdNfON2EmLWZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}