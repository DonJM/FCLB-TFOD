{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "FCLB_TFOD.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DonJM/FCLB-TFOD/blob/master/FCLB_TFOD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZzzCHKQnpHI"
      },
      "source": [
        "# Import and Install Modules and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIV8j7m1jXDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7affcd1-0a77-4160-bcfa-8ddfb66c6bd7"
      },
      "source": [
        "!pip install wget\n",
        "\n",
        "#import neccessary python modules and libraries\n",
        "import os\n",
        "import shutil\n",
        "from PIL import ImageEnhance\n",
        "from PIL import Image\n",
        "import uuid\n",
        "import tarfile\n",
        "import wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=e0ac2dd2eef6294eba9f95427d119f3df3e073cf712d18285f491bc8ca154ddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78s0FVL4mMg5"
      },
      "source": [
        "# Adding Classes for Path Setup and Project Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My2TVbX8lvMq"
      },
      "source": [
        "class Setup_Path: \n",
        "\n",
        "    LABELS = [\"fresh\", \"rotten\"]\n",
        "\n",
        "    def getFiles(self):\n",
        "      files = {\n",
        "          \"LABELMAP\":os.path.join(self.getWorkspaces()['ANNOTATIONS_PATH'], \"label_map.pbtxt\"),\n",
        "          'TFRECORD_SCRIPT':os.path.join(self.getWorkspaces()['PREPROCESSING_PATH'], 'generate_tfrecord.py'),\n",
        "          \"PRETRAINED_MODEL_NAME\": 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8',\n",
        "          \"PRETRAINED_MODEL_URL\": 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz', \n",
        "          \"PIPELINE_CONFIG\": os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"my_ssd_mobnet\", \"pipeline.config\")\n",
        "      }\n",
        "\n",
        "      return files\n",
        "\n",
        "    def getWorkspaces(self):\n",
        "        paths = {\n",
        "            \"ADDONS_PATH\":os.path.join(\"Tensorflow\", \"addons\"),\n",
        "            \"LABEL_IMG_PATH\":os.path.join(\"Tensorflow\", \"addons\", \"labelImg\"),\n",
        "            \"TFOD_API_PATH\":\"Tensorflow\",\n",
        "            \"WORKSPACE_PATH\":os.path.join(\"Tensorflow\", \"workspace\"),\n",
        "            \"TRAINING_DEMO_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\"),\n",
        "            \"ANNOTATIONS_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"annotations\"),\n",
        "            \"IMAGES_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"images\"),\n",
        "            \"TRAINING_IMAGES_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"images\", \"train\"),\n",
        "            \"TESTING_IMAGES_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"images\", \"test\"),\n",
        "            \"PRETRAINED_MODELS_PATH\":os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", \"pre-trained-models\"),\n",
        "            \"PREPROCESSED_IMG\":os.path.join(\"Tensorflow\", \"addons\", \"preprocessedImg\"),\n",
        "            \"ORIGINAL_IMGS\":os.path.join(\"Tensorflow\", \"addons\", \"originalImg\"),   \n",
        "            \"PREPROCESSING_PATH\":os.path.join(\"Tensorflow\", \"scripts\", \"preprocessing\"),\n",
        "            \"PROTOS_PATH\":os.path.join(\"Tensorflow\", \"Google-Protobuf\"),\n",
        "            'CHECKPOINT_PATH': os.path.join(\"Tensorflow\", \"workspace\", \"training_demo\", 'my_ssd_mobnet'),\n",
        "            'TFJS_PATH':os.path.join('Tensorflow', 'workspace', \"training_demo\",'my_ssd_mobnet', 'tfjsexport'), \n",
        "            'TFLITE_PATH':os.path.join('Tensorflow', 'workspace', \"training_demo\",'my_ssd_mobnet', 'tfliteexport'),\n",
        "            'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace',\"training_demo\",'my_ssd_mobnet', 'export'), \n",
        "        }\n",
        "\n",
        "        return paths\n",
        "\n",
        "    # def set_main_paths(self):\n",
        "    #     for path in self.get_main_paths().values():\n",
        "    #         if not os.path.exists(path):\n",
        "    #             os.makedirs(path)\n",
        "\n",
        "    # def get_image_paths(self):\n",
        "    #     path = {\n",
        "    #         \"ORIGINAL_IMAGES_PATH\" : [\"workspace\\datasets\\original_images\\Fresh_Ripe\", \"workspace\\datasets\\original_images\\Fresh_Unripe\", \"workspace\\datasets\\original_images\\Rotten_Ripe\", \"workspace\\datasets\\original_images\\Rotten_Unripe\"],\n",
        "    #         \"PREPROCESSED_IMAGES_PATH\" : [\"workspace\\datasets\\preprocessed_images\\Fresh_Ripe\", \"workspace\\datasets\\preprocessed_images\\Fresh_Unripe\", \"workspace\\datasets\\preprocessed_images\\Rotten_Ripe\", \"workspace\\datasets\\preprocessed_images\\Rotten_Unripe\"],\n",
        "    #     }\n",
        "\n",
        "    #     return path\n",
        "\n",
        "    # def set_image_paths(self):\n",
        "    #     for path in self.get_image_paths().values():\n",
        "    #         for label in path:\n",
        "    #             if not os.path.exists(label):\n",
        "    #                 os.makedirs(label)\n",
        "\n",
        "    # def getFiles(self):\n",
        "    #     files = {\n",
        "    #         'PIPELINE_CONFIG':os.path.join(self.get_paths()['MODELS_PATH'], self.custom_name, 'pipeline.config'),\n",
        "    #         'TF_RECORD_SCRIPT':os.path.join(self.get_paths()['TFRECORD_GENERATOR_PATH'], self.tfrecord_name),\n",
        "    #         'LABEL_MAP':os.path.join(self.get_paths()['ANOTATIONS_PATH'], self.map_name),\n",
        "    #     }\n",
        "    #     return files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lD26arHmG7-"
      },
      "source": [
        "class FCLB_Datasets:\n",
        "    #class' constructor\n",
        "    def __init__(self, setup):\n",
        "        self.setup = setup\n",
        "    \n",
        "    #acquiring uncategorized dataset\n",
        "    def get_original_dataset(self, num1, num2, label):\n",
        "        images_path = self.setup.getWorkspaces()['ORIGINAL_IMGS']\n",
        "        path = os.path.join(images_path, label)\n",
        "\n",
        "        files = [\"{}\".format(i) for i in os.listdir(path)[num1:num2]]\n",
        "\n",
        "        return files\n",
        "\n",
        "    def copy_image_file(self, num1, num2, srcPath, dstPath):\n",
        "\n",
        "        for label in self.setup.LABELS:\n",
        "            for file in self.get_original_dataset(num1, num2, label):\n",
        "                dst = os.path.join(dstPath, label, file)\n",
        "                src = os.path.join(srcPath, label, file)\n",
        "                shutil.copyfile(src, dst)\n",
        "\n",
        "    #I call it segment function, wala na koy mahunahunaan\n",
        "    def segment(self):\n",
        "        original_dir = self.setup.getWorkspaces()['ORIGINAL_IMGS']\n",
        "        target_dir = self.setup.getWorkspaces()['PREPROCESSED_IMG']\n",
        "        labels = self.setup.LABELS\n",
        "\n",
        "        for label in labels:\n",
        "            original = os.path.join(original_dir, label)\n",
        "            target = os.path.join(target_dir, label)\n",
        "            for img in os.listdir(original):\n",
        "                self.segmentation(original, target, img, label)\n",
        " \n",
        "\n",
        "    #this function used to segment an image file, it actually resize image, add contrast and lightness\n",
        "    #and save it to the target directory\n",
        "    #the purpose of uuid module is to give unique id or name to an image file\n",
        "    def segmentation(self, base_dir, target_dir, fname, label):\n",
        "        image = Image.open(os.path.join(base_dir, fname))\n",
        "        size = (320,320)\n",
        "        image.thumbnail(size)\n",
        "\n",
        "        n = random.randint(0,360)\n",
        "        image = np.asarray(image)\n",
        "        \n",
        "        rotate=iaa.Affine(rotate=(-(n), n))\n",
        "        rotated_image=rotate.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), rotated_image)\n",
        "        \n",
        "        \n",
        "        gaussian_noise=iaa.AdditiveGaussianNoise(10,20)\n",
        "        noise_image=gaussian_noise.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), noise_image)\n",
        "        \n",
        "        \n",
        "        crop = iaa.Crop(percent=(0, 0.3)) # crop image\n",
        "        crop_image=crop.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), crop_image)\n",
        "        \n",
        "        \n",
        "        shear = iaa.Affine(shear=(0,40))\n",
        "        shear_image=shear.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), shear_image)\n",
        "        \n",
        "        \n",
        "        #flipping image horizontally\n",
        "        flip_hr=iaa.Fliplr(p=1.0)\n",
        "        flip_hr_image= flip_hr.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), flip_hr_image)\n",
        "        \n",
        "        \n",
        "        flip_vr=iaa.Flipud(p=1.0)\n",
        "        flip_vr_image= flip_vr.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), flip_vr_image)\n",
        "        \n",
        "        \n",
        "        contrast=iaa.GammaContrast(gamma=0.3)\n",
        "        contrast_image =contrast.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), contrast_image)\n",
        "        \n",
        "        contrast=iaa.GammaContrast(gamma=0.9)\n",
        "        contrast_image =contrast.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), contrast_image)\n",
        "        \n",
        "        \n",
        "        scale_im=iaa.Affine(scale={\"x\": (1.5, 1.0), \"y\": (1.5, 1.0)})\n",
        "        scale_image =scale_im.augment_image(image)\n",
        "        imageio.imsave(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())), scale_image)\n",
        "        \n",
        "#         contrast = ImageEnhance.Contrast(image)\n",
        "#         contrast.enhance(1.8).save(os.path.join(target_dir, label + \"-\"+ '{}.jpg'.format(uuid.uuid1())))\n",
        " \n",
        "#         brightness = ImageEnhance.Brightness(image)\n",
        "#         brightness.enhance(1.2).save(os.path.join(target_dir, label +\"-\"+ '{}.jpg'.format(uuid.uuid1())))\n",
        "\n",
        "    #compressed file for github upload\n",
        "    def compressed(self):\n",
        "        path = self.getDir('PREPROCESSED_IMAGES_PATH')\n",
        "        sub_paths = self.getSubDirectories(path)\n",
        "        ARCHIVE_PATH = os.path.join(path, 'preprocessed_images.tar.gz')\n",
        "        tar = tarfile.open(ARCHIVE_PATH, \"w:gz\")\n",
        "        for sub_path in sub_paths:\n",
        "            dir = os.path.join(path, sub_path)\n",
        "            tar.add(dir)\n",
        "        tar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC41kBtRm0Yp"
      },
      "source": [
        "# Preparing Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ9E39oJvC4L"
      },
      "source": [
        "Creating a workspace directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxX3KjTwm38H"
      },
      "source": [
        "setup = Setup_Path()\n",
        "workspaces = setup.getWorkspaces()\n",
        "for workspace in workspaces.values():\n",
        "  if not os.path.exists(workspace):\n",
        "    os.makedirs(workspace)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU8jvyVRl3Bw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "36753d61-0ec6-4732-d7d0-2c52a7cc4ef3"
      },
      "source": [
        "!unzip /content/train.zip\n",
        "shutil.move('/content/fresh', setup.getWorkspaces()['ORIGINAL_IMGS'])\n",
        "shutil.move('/content/rotten', setup.getWorkspaces()['ORIGINAL_IMGS'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train.zip\n",
            "replace fresh/Fresh.526.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace fresh/Fresh.534.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace fresh/Fresh.534.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fresh/Fresh.534.jpg     \n",
            "replace fresh/Fresh.718.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fresh/Fresh.718.jpg     \n",
            "replace fresh/Fresh.729.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fresh/Fresh.729.jpg     \n",
            "replace fresh/Fresh.743.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fresh/Fresh.743.jpg     \n",
            "replace fresh/Fresh.799.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: fresh/Fresh.799.jpg     \n",
            "replace rotten/Rotten.120.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.120.jpg   \n",
            "replace rotten/Rotten.1538.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.1538.jpg  \n",
            "replace rotten/Rotten.1553.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.1553.jpg  \n",
            "replace rotten/Rotten.1638.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.1638.jpg  \n",
            "replace rotten/Rotten.1679.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.1679.jpg  \n",
            "replace rotten/Rotten.1826.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: rotten/Rotten.1826.jpg  \n",
            "y\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tensorflow/addons/originalImg/rotten'"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4kFQ6HvBPLs"
      },
      "source": [
        "Create label directory for original images and preprocessed images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E57aJQJaBZwk"
      },
      "source": [
        "for label in setup.LABELS:\n",
        "  preprocessedImg_labelPath = os.path.join(setup.getWorkspaces()['PREPROCESSED_IMG'], label)\n",
        "  if not os.path.exists(preprocessedImg_labelPath):\n",
        "    os.makedirs(preprocessedImg_labelPath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V3MqcrhCw31"
      },
      "source": [
        "segment images and copy to preprocessed directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTt-b7Kf4i8w"
      },
      "source": [
        "dataset = FCLB_Datasets(setup)\n",
        "dataset.segment()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAE7c2IXssvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "335952b1-6992-4f45-c6c4-bf835cc4b441"
      },
      "source": [
        "!cd /content/Tensorflow && zip {setup.getWorkspaces()['PREPROCESSED_IMG']}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "zip error: Nothing to do! (Tensorflow/addons/preprocessedImg.zip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxfLOMGHcVz"
      },
      "source": [
        "# Image Labelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6s2JNoIHayP",
        "outputId": "4da497a5-7042-470b-d3ef-1f7c5b93bd12"
      },
      "source": [
        "labelImg = setup.getWorkspaces()['LABEL_IMG_PATH']\n",
        "!cd {labelImg} && git clone https://github.com/tzutalin/labelImg.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'labelImg'...\n",
            "remote: Enumerating objects: 1846, done.\u001b[K\n",
            "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 1846 (delta 37), reused 55 (delta 18), pack-reused 1759\u001b[K\n",
            "Receiving objects: 100% (1846/1846), 232.81 MiB | 41.39 MiB/s, done.\n",
            "Resolving deltas: 100% (1084/1084), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_mc2redH-cK",
        "outputId": "bc071297-da4d-47f4-ae0b-be68a15cee4a"
      },
      "source": [
        "labelImg = os.path.join(setup.getWorkspaces()['LABEL_IMG_PATH'], \"labelImg\")\n",
        "!cd {labelImg} && pip install pyqt5\n",
        "!cd {labelImg} && pyrcc5 -o libs/resources.py resources.qrc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyqt5 in /usr/local/lib/python3.7/dist-packages (5.15.4)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.8 in /usr/local/lib/python3.7/dist-packages (from pyqt5) (12.9.0)\n",
            "Requirement already satisfied: PyQt5-Qt5>=5.15 in /usr/local/lib/python3.7/dist-packages (from pyqt5) (5.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umiIKPZ2o1h-"
      },
      "source": [
        "Compress of Image Labeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l09c8_mln0C2"
      },
      "source": [
        "TRAIN_PATH = os.path.join(setup.getWorkspaces()['PREPROCESSED_IMG'], 'train')\n",
        "TEST_PATH = os.path.join(setup.getWorkspaces()['PREPROCESSED_IMG'], 'test')\n",
        "ARCHIVE_PATH = os.path.join(setup.getWorkspaces()['PREPROCESSED_IMG'], 'archive.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzJeTt8_oBHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c79ee2-0a52-47fe-91dc-1524080175ba"
      },
      "source": [
        "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: Tensorflow/addons/preprocessedImg/train: Cannot stat: No such file or directory\n",
            "tar: Tensorflow/addons/preprocessedImg/test: Cannot stat: No such file or directory\n",
            "tar: Exiting with failure status due to previous errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aapLubxmPV5f"
      },
      "source": [
        "# Partition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kY92xAFPs7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d3d8d811-82e1-4a65-c447-a9f08494c89f"
      },
      "source": [
        "url = \"https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/d0e545609c5f7f49f39abc7b6a38cec3/partition_dataset.py\"\n",
        "src = wget.download(url)\n",
        "dst = setup.getWorkspaces()['PREPROCESSING_PATH']\n",
        "shutil.move(src, dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tensorflow/scripts/preprocessing/partition_dataset.py'"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nnlfqUdacOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71e4808-c478-4f46-9dc5-64cce3c4060e"
      },
      "source": [
        "images_path = setup.getWorkspaces()['IMAGES_PATH']\n",
        "!cd {dst} python partition_dataset.py -x -i {images_path} -r 0.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: too many arguments\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNwjmYxpjAsE"
      },
      "source": [
        "# Download Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLUHiHepje2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e0bc6b-677a-48b0-8a39-ff8f23f26a1f"
      },
      "source": [
        "tfod_api = setup.getWorkspaces()['TFOD_API_PATH']\n",
        "!cd {tfod_api} && git clone https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 61146, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 61146 (delta 15), reused 22 (delta 8), pack-reused 61113\u001b[K\n",
            "Receiving objects: 100% (61146/61146), 573.99 MiB | 29.50 MiB/s, done.\n",
            "Resolving deltas: 100% (42588/42588), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCU3DQZ6k5EY"
      },
      "source": [
        "# Install Object Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv3dM-Fjhhjz"
      },
      "source": [
        "research_path = os.path.join(setup.getWorkspaces()['TFOD_API_PATH'], 'models', 'research')\n",
        "!cd {research_path} && cp object_detection/packages/tf2/setup.py setup.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgVwgIwDlmB6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0978dd20-e3db-4705-f7bd-b1584c897f4f"
      },
      "source": [
        "url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "src = wget.download(url)\n",
        "protos_path = setup.getWorkspaces()['PROTOS_PATH']\n",
        "shutil.move(src, protos_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tensorflow/Google-Protobuf/protoc-3.15.6-win64.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nh_rvea2eayt",
        "outputId": "eb25c0a8-5714-48d2-9447-f5caf5218645"
      },
      "source": [
        "!apt-get install protobuf-compiler\n",
        "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 43.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 47.3 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text>=2.5.0\n",
            "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 30.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 34.3 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.1 MB 49 kB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 43.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.34.0)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.39.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.6.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting future<1.0.0,>=0.18.2\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 33.7 MB/s \n",
            "\u001b[?25hCollecting avro-python3\n",
            "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 753 kB/s \n",
            "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Collecting fastavro<2,>=0.21.4\n",
            "  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 50.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n",
            "Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1663491 sha256=b8f854249b2d8a25b1ea432de4320e875e90bbd0b4dcd281d95de127fd72f160\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z7pcabl4/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=dde2320c378d3a93371b82d974fab30fdfa4078c892d7c893be5fa38eaa5b389\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=d95d2f2863dca44110ca0966b3f0cacb203a80138d5f53013fa5370c22a3b6b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=a07baace85f44ba656232d8547cfe7d1d993642b3f86dde3c6a9dd01524d8531\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=3b8345ef6a16552385259ccfdef940623f1e30d70a08dfd4967d082a078135f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=02d5147b0e522267bc1040e61fb26d69a8255e70ebd09b715fb22d6e6f2fecc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n",
            "Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5SWZ2MPaN2-",
        "outputId": "bad05abb-1467-4226-94f5-20c8b8d1b930"
      },
      "source": [
        "# !cd {research_path} && python object_detection/builders/model_builder_tf2_test.py\n",
        "VERIFICATION_SCRIPT = os.path.join(research_path, 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-02 05:57:33.119854: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-09-02 05:57:33.119940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (356291ceeb64): /proc/driver/nvidia/version does not exist\n",
            "Running tests under Python 3.7.11: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "W0902 05:57:33.460692 140427587336064 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.83s\n",
            "I0902 05:57:33.951330 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.83s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.64s\n",
            "I0902 05:57:34.588632 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.64s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
            "I0902 05:57:34.940746 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n",
            "I0902 05:57:35.249220 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.31s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "W0902 05:57:35.252070 140427587336064 mobilenet_v2.py:297] `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.87s\n",
            "I0902 05:57:38.116128 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.87s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0902 05:57:38.117440 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "I0902 05:57:38.151584 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I0902 05:57:38.171375 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "I0902 05:57:38.192507 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "I0902 05:57:38.325543 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I0902 05:57:38.456901 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "I0902 05:57:38.585843 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "I0902 05:57:38.717786 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "I0902 05:57:38.857144 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0902 05:57:38.891985 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0902 05:57:39.290601 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0902 05:57:39.290812 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
            "I0902 05:57:39.290900 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
            "I0902 05:57:39.293739 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:39.314191 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:39.314411 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:39.391722 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:39.392001 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:39.591219 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:39.591456 140427587336064 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0902 05:57:39.793510 140427587336064 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0902 05:57:39.793756 140427587336064 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0902 05:57:40.128340 140427587336064 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0902 05:57:40.128545 140427587336064 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0902 05:57:40.432132 140427587336064 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0902 05:57:40.432362 140427587336064 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0902 05:57:40.889369 140427587336064 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0902 05:57:40.889578 140427587336064 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0902 05:57:41.006118 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0902 05:57:41.073331 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:41.142548 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0902 05:57:41.142750 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n",
            "I0902 05:57:41.142836 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n",
            "I0902 05:57:41.146024 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:41.167982 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:41.168177 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:41.329719 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:41.329980 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:41.630366 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:41.630584 140427587336064 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0902 05:57:41.922667 140427587336064 efficientnet_model.py:147] round_filter input=40 output=40\n",
            "I0902 05:57:41.922913 140427587336064 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0902 05:57:42.318734 140427587336064 efficientnet_model.py:147] round_filter input=80 output=80\n",
            "I0902 05:57:42.318965 140427587336064 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0902 05:57:42.724288 140427587336064 efficientnet_model.py:147] round_filter input=112 output=112\n",
            "I0902 05:57:42.724547 140427587336064 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0902 05:57:43.310896 140427587336064 efficientnet_model.py:147] round_filter input=192 output=192\n",
            "I0902 05:57:43.311339 140427587336064 efficientnet_model.py:147] round_filter input=320 output=320\n",
            "I0902 05:57:43.581674 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
            "I0902 05:57:43.644758 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:43.869025 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0902 05:57:43.869285 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n",
            "I0902 05:57:43.869397 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n",
            "I0902 05:57:43.873173 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:43.901528 140427587336064 efficientnet_model.py:147] round_filter input=32 output=32\n",
            "I0902 05:57:43.901737 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:44.051219 140427587336064 efficientnet_model.py:147] round_filter input=16 output=16\n",
            "I0902 05:57:44.051438 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:44.355638 140427587336064 efficientnet_model.py:147] round_filter input=24 output=24\n",
            "I0902 05:57:44.355873 140427587336064 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0902 05:57:44.643688 140427587336064 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0902 05:57:44.643934 140427587336064 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0902 05:57:45.046123 140427587336064 efficientnet_model.py:147] round_filter input=80 output=88\n",
            "I0902 05:57:45.046344 140427587336064 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0902 05:57:45.470304 140427587336064 efficientnet_model.py:147] round_filter input=112 output=120\n",
            "I0902 05:57:45.470534 140427587336064 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0902 05:57:46.059396 140427587336064 efficientnet_model.py:147] round_filter input=192 output=208\n",
            "I0902 05:57:46.059613 140427587336064 efficientnet_model.py:147] round_filter input=320 output=352\n",
            "I0902 05:57:46.347544 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=1408\n",
            "I0902 05:57:46.419129 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:46.494084 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0902 05:57:46.494296 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n",
            "I0902 05:57:46.494405 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n",
            "I0902 05:57:46.496466 140427587336064 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0902 05:57:46.516599 140427587336064 efficientnet_model.py:147] round_filter input=32 output=40\n",
            "I0902 05:57:46.516836 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:46.667110 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:46.667335 140427587336064 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0902 05:57:46.965340 140427587336064 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0902 05:57:46.965576 140427587336064 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0902 05:57:47.257232 140427587336064 efficientnet_model.py:147] round_filter input=40 output=48\n",
            "I0902 05:57:47.257468 140427587336064 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0902 05:57:47.782708 140427587336064 efficientnet_model.py:147] round_filter input=80 output=96\n",
            "I0902 05:57:47.782943 140427587336064 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0902 05:57:48.323997 140427587336064 efficientnet_model.py:147] round_filter input=112 output=136\n",
            "I0902 05:57:48.324207 140427587336064 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0902 05:57:49.063499 140427587336064 efficientnet_model.py:147] round_filter input=192 output=232\n",
            "I0902 05:57:49.063725 140427587336064 efficientnet_model.py:147] round_filter input=320 output=384\n",
            "I0902 05:57:49.349078 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=1536\n",
            "I0902 05:57:49.418801 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:49.744398 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0902 05:57:49.744620 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n",
            "I0902 05:57:49.744740 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0902 05:57:49.746855 140427587336064 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0902 05:57:49.765888 140427587336064 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0902 05:57:49.766124 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:49.925570 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:49.925812 140427587336064 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0902 05:57:50.341436 140427587336064 efficientnet_model.py:147] round_filter input=24 output=32\n",
            "I0902 05:57:50.341673 140427587336064 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0902 05:57:50.740116 140427587336064 efficientnet_model.py:147] round_filter input=40 output=56\n",
            "I0902 05:57:50.740357 140427587336064 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0902 05:57:51.362705 140427587336064 efficientnet_model.py:147] round_filter input=80 output=112\n",
            "I0902 05:57:51.362910 140427587336064 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0902 05:57:52.013973 140427587336064 efficientnet_model.py:147] round_filter input=112 output=160\n",
            "I0902 05:57:52.014254 140427587336064 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0902 05:57:53.036825 140427587336064 efficientnet_model.py:147] round_filter input=192 output=272\n",
            "I0902 05:57:53.037126 140427587336064 efficientnet_model.py:147] round_filter input=320 output=448\n",
            "I0902 05:57:53.347937 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=1792\n",
            "I0902 05:57:53.426084 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:53.518672 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0902 05:57:53.518905 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n",
            "I0902 05:57:53.519028 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n",
            "I0902 05:57:53.521035 140427587336064 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0902 05:57:53.539774 140427587336064 efficientnet_model.py:147] round_filter input=32 output=48\n",
            "I0902 05:57:53.540006 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:53.774397 140427587336064 efficientnet_model.py:147] round_filter input=16 output=24\n",
            "I0902 05:57:53.774617 140427587336064 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0902 05:57:54.280878 140427587336064 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0902 05:57:54.281118 140427587336064 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0902 05:57:54.784938 140427587336064 efficientnet_model.py:147] round_filter input=40 output=64\n",
            "I0902 05:57:54.785166 140427587336064 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0902 05:57:55.547181 140427587336064 efficientnet_model.py:147] round_filter input=80 output=128\n",
            "I0902 05:57:55.547403 140427587336064 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0902 05:57:56.614813 140427587336064 efficientnet_model.py:147] round_filter input=112 output=176\n",
            "I0902 05:57:56.615058 140427587336064 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0902 05:57:57.839798 140427587336064 efficientnet_model.py:147] round_filter input=192 output=304\n",
            "I0902 05:57:57.840029 140427587336064 efficientnet_model.py:147] round_filter input=320 output=512\n",
            "I0902 05:57:58.428255 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=2048\n",
            "I0902 05:57:58.513071 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:57:58.621744 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0902 05:57:58.621965 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0902 05:57:58.622054 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0902 05:57:58.624068 140427587336064 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0902 05:57:58.642663 140427587336064 efficientnet_model.py:147] round_filter input=32 output=56\n",
            "I0902 05:57:58.642873 140427587336064 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0902 05:57:58.872261 140427587336064 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0902 05:57:58.872463 140427587336064 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0902 05:57:59.460626 140427587336064 efficientnet_model.py:147] round_filter input=24 output=40\n",
            "I0902 05:57:59.460821 140427587336064 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0902 05:58:00.051663 140427587336064 efficientnet_model.py:147] round_filter input=40 output=72\n",
            "I0902 05:58:00.051899 140427587336064 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0902 05:58:00.907136 140427587336064 efficientnet_model.py:147] round_filter input=80 output=144\n",
            "I0902 05:58:00.907355 140427587336064 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0902 05:58:01.812641 140427587336064 efficientnet_model.py:147] round_filter input=112 output=200\n",
            "I0902 05:58:01.812862 140427587336064 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0902 05:58:03.682587 140427587336064 efficientnet_model.py:147] round_filter input=192 output=344\n",
            "I0902 05:58:03.682811 140427587336064 efficientnet_model.py:147] round_filter input=320 output=576\n",
            "I0902 05:58:04.290292 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=2304\n",
            "I0902 05:58:04.383164 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0902 05:58:04.509792 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0902 05:58:04.510050 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n",
            "I0902 05:58:04.510157 140427587336064 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n",
            "I0902 05:58:04.512400 140427587336064 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0902 05:58:04.531904 140427587336064 efficientnet_model.py:147] round_filter input=32 output=64\n",
            "I0902 05:58:04.532132 140427587336064 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0902 05:58:04.845099 140427587336064 efficientnet_model.py:147] round_filter input=16 output=32\n",
            "I0902 05:58:04.845335 140427587336064 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0902 05:58:05.530644 140427587336064 efficientnet_model.py:147] round_filter input=24 output=48\n",
            "I0902 05:58:05.530872 140427587336064 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0902 05:58:06.260003 140427587336064 efficientnet_model.py:147] round_filter input=40 output=80\n",
            "I0902 05:58:06.260238 140427587336064 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0902 05:58:07.337758 140427587336064 efficientnet_model.py:147] round_filter input=80 output=160\n",
            "I0902 05:58:07.338010 140427587336064 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0902 05:58:08.532366 140427587336064 efficientnet_model.py:147] round_filter input=112 output=224\n",
            "I0902 05:58:08.532687 140427587336064 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0902 05:58:10.561858 140427587336064 efficientnet_model.py:147] round_filter input=192 output=384\n",
            "I0902 05:58:10.562108 140427587336064 efficientnet_model.py:147] round_filter input=320 output=640\n",
            "I0902 05:58:11.795421 140427587336064 efficientnet_model.py:147] round_filter input=1280 output=2560\n",
            "I0902 05:58:11.906526 140427587336064 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 33.18s\n",
            "I0902 05:58:12.068979 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 33.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0902 05:58:12.077026 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0902 05:58:12.079342 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0902 05:58:12.080071 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0902 05:58:12.082022 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0902 05:58:12.083800 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0902 05:58:12.084420 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0902 05:58:12.085688 140427587336064 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 38.962s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5w9HanHSAG2B",
        "outputId": "ea962f61-189e-45ab-d639-659d84941472"
      },
      "source": [
        "!pip list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------\n",
            "absl-py                       0.12.0\n",
            "alabaster                     0.7.12\n",
            "albumentations                0.1.12\n",
            "altair                        4.1.0\n",
            "apache-beam                   2.32.0\n",
            "appdirs                       1.4.4\n",
            "argcomplete                   1.12.3\n",
            "argon2-cffi                   21.1.0\n",
            "arviz                         0.11.2\n",
            "astor                         0.8.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atari-py                      0.2.9\n",
            "atomicwrites                  1.4.0\n",
            "attrs                         21.2.0\n",
            "audioread                     2.1.9\n",
            "autograd                      1.3\n",
            "avro-python3                  1.9.2.1\n",
            "Babel                         2.9.1\n",
            "backcall                      0.2.0\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        4.0.0\n",
            "blis                          0.4.1\n",
            "bokeh                         2.3.3\n",
            "Bottleneck                    1.3.2\n",
            "branca                        0.4.2\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.6\n",
            "cached-property               1.5.2\n",
            "cachetools                    4.2.2\n",
            "catalogue                     1.0.0\n",
            "certifi                       2021.5.30\n",
            "cffi                          1.14.6\n",
            "cftime                        1.5.0\n",
            "chardet                       3.0.4\n",
            "charset-normalizer            2.0.4\n",
            "clang                         5.0\n",
            "click                         7.1.2\n",
            "cloudpickle                   1.3.0\n",
            "cmake                         3.12.0\n",
            "cmdstanpy                     0.9.5\n",
            "colorama                      0.4.4\n",
            "colorcet                      2.0.6\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.3.2\n",
            "coverage                      3.7.1\n",
            "coveralls                     0.5\n",
            "crcmod                        1.7\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.2.6\n",
            "cvxpy                         1.0.31\n",
            "cycler                        0.10.0\n",
            "cymem                         2.0.5\n",
            "Cython                        0.29.24\n",
            "daft                          0.0.4\n",
            "dask                          2.12.0\n",
            "datascience                   0.10.6\n",
            "debugpy                       1.0.0\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "descartes                     1.1.0\n",
            "dill                          0.3.1.1\n",
            "distributed                   1.25.3\n",
            "dlib                          19.18.0\n",
            "dm-tree                       0.1.6\n",
            "docopt                        0.6.2\n",
            "docutils                      0.17.1\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.278\n",
            "easydict                      1.9\n",
            "ecos                          2.0.7.post1\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                2.2.5\n",
            "entrypoints                   0.3\n",
            "ephem                         4.0.0.2\n",
            "et-xmlfile                    1.1.0\n",
            "fa2                           0.3.5\n",
            "fastai                        1.0.61\n",
            "fastavro                      1.4.4\n",
            "fastdtw                       0.3.4\n",
            "fastprogress                  1.0.0\n",
            "fastrlock                     0.6\n",
            "fbprophet                     0.7.1\n",
            "feather-format                0.4.1\n",
            "filelock                      3.0.12\n",
            "firebase-admin                4.4.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         1.1.4\n",
            "flatbuffers                   1.12\n",
            "folium                        0.8.3\n",
            "future                        0.18.2\n",
            "gast                          0.4.0\n",
            "GDAL                          2.2.2\n",
            "gdown                         3.6.4\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.4.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               1.26.3\n",
            "google-api-python-client      1.12.8\n",
            "google-auth                   1.34.0\n",
            "google-auth-httplib2          0.0.4\n",
            "google-auth-oauthlib          0.4.5\n",
            "google-cloud-bigquery         1.21.0\n",
            "google-cloud-bigquery-storage 1.1.0\n",
            "google-cloud-core             1.0.3\n",
            "google-cloud-datastore        1.8.0\n",
            "google-cloud-firestore        1.7.0\n",
            "google-cloud-language         1.2.0\n",
            "google-cloud-storage          1.18.1\n",
            "google-cloud-translate        1.5.0\n",
            "google-colab                  1.0.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        0.4.1\n",
            "googleapis-common-protos      1.53.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      1.1.1\n",
            "grpcio                        1.39.0\n",
            "gspread                       3.0.1\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.17.3\n",
            "h5py                          3.1.0\n",
            "hdfs                          2.6.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.1.3\n",
            "holidays                      0.10.5.2\n",
            "holoviews                     1.14.5\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "httplib2shim                  0.0.3\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "ideep4py                      2.0.0.post3\n",
            "idna                          2.10\n",
            "imageio                       2.4.1\n",
            "imagesize                     1.2.0\n",
            "imbalanced-learn              0.4.3\n",
            "imblearn                      0.0\n",
            "imgaug                        0.2.9\n",
            "importlib-metadata            4.6.4\n",
            "importlib-resources           5.2.2\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "iniconfig                     1.1.1\n",
            "intel-openmp                  2021.3.0\n",
            "intervaltree                  2.1.0\n",
            "ipykernel                     4.10.1\n",
            "ipython                       5.5.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.6.3\n",
            "itsdangerous                  1.1.0\n",
            "jax                           0.2.19\n",
            "jaxlib                        0.1.70+cuda110\n",
            "jdcal                         1.4.1\n",
            "jedi                          0.18.0\n",
            "jieba                         0.42.1\n",
            "Jinja2                        2.11.3\n",
            "joblib                        1.0.1\n",
            "jpeg4py                       0.1.4\n",
            "jsonschema                    2.6.0\n",
            "jupyter                       1.0.0\n",
            "jupyter-client                5.3.5\n",
            "jupyter-console               5.2.0\n",
            "jupyter-core                  4.7.1\n",
            "jupyterlab-pygments           0.1.2\n",
            "jupyterlab-widgets            1.0.0\n",
            "kaggle                        1.5.12\n",
            "kapre                         0.3.5\n",
            "keras                         2.6.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.3.1\n",
            "korean-lunar-calendar         0.2.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.34.0\n",
            "lmdb                          0.99\n",
            "LunarCalendar                 0.0.9\n",
            "lvis                          0.5.3\n",
            "lxml                          4.2.6\n",
            "Markdown                      3.3.4\n",
            "MarkupSafe                    2.0.1\n",
            "matplotlib                    3.2.2\n",
            "matplotlib-inline             0.1.2\n",
            "matplotlib-venn               0.11.6\n",
            "missingno                     0.5.0\n",
            "mistune                       0.8.4\n",
            "mizani                        0.6.0\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                8.8.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.2\n",
            "multiprocess                  0.70.12.2\n",
            "multitasking                  0.0.9\n",
            "murmurhash                    1.0.5\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.5.4\n",
            "nbconvert                     5.6.1\n",
            "nbformat                      5.1.3\n",
            "nest-asyncio                  1.5.1\n",
            "netCDF4                       1.5.7\n",
            "networkx                      2.6.2\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.2.5\n",
            "notebook                      5.3.1\n",
            "numba                         0.51.2\n",
            "numexpr                       2.7.3\n",
            "numpy                         1.19.5\n",
            "nvidia-ml-py3                 7.352.0\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.1.1\n",
            "object-detection              0.1\n",
            "okgrade                       0.4.3\n",
            "opencv-contrib-python         4.1.2.30\n",
            "opencv-python                 4.1.2.30\n",
            "opencv-python-headless        4.5.3.56\n",
            "openpyxl                      2.5.9\n",
            "opt-einsum                    3.3.0\n",
            "orjson                        3.6.3\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     21.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.1.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.13.3\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.4.3\n",
            "panel                         0.12.1\n",
            "param                         1.11.1\n",
            "parso                         0.8.2\n",
            "pathlib                       1.0.1\n",
            "patsy                         0.5.1\n",
            "pep517                        0.11.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        7.1.2\n",
            "pip                           21.1.3\n",
            "pip-tools                     6.2.0\n",
            "plac                          1.1.3\n",
            "plotly                        4.4.1\n",
            "plotnine                      0.6.0\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.4.0\n",
            "portalocker                   2.3.2\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.1\n",
            "preshed                       3.0.5\n",
            "prettytable                   2.1.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.11.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                1.0.18\n",
            "protobuf                      3.17.3\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.7.6.1\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.10.0\n",
            "py-cpuinfo                    8.0.0\n",
            "pyarrow                       3.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.2\n",
            "pycparser                     2.20\n",
            "pyct                          0.4.8\n",
            "pydata-google-auth            1.2.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyemd                         0.5.1\n",
            "pyerfa                        2.0.0\n",
            "pyglet                        1.5.0\n",
            "Pygments                      2.6.1\n",
            "pygobject                     3.26.1\n",
            "pymc3                         3.11.2\n",
            "PyMeeus                       0.5.11\n",
            "pymongo                       3.12.0\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.5\n",
            "pyparsing                     2.4.7\n",
            "pyrsistent                    0.18.0\n",
            "pysndfile                     1.3.8\n",
            "PySocks                       1.7.1\n",
            "pystan                        2.19.1.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-chess                  0.23.11\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.15\n",
            "python-slugify                5.0.2\n",
            "python-utils                  2.5.6\n",
            "pytz                          2018.9\n",
            "pyviz-comms                   2.1.0\n",
            "PyWavelets                    1.1.1\n",
            "PyYAML                        5.4.1\n",
            "pyzmq                         22.2.1\n",
            "qdldl                         0.1.5.post0\n",
            "qtconsole                     5.1.1\n",
            "QtPy                          1.10.0\n",
            "regex                         2019.12.20\n",
            "requests                      2.26.0\n",
            "requests-oauthlib             1.3.0\n",
            "resampy                       0.2.2\n",
            "retrying                      1.3.3\n",
            "rpy2                          3.4.5\n",
            "rsa                           4.7.2\n",
            "sacrebleu                     2.0.0\n",
            "scikit-image                  0.16.2\n",
            "scikit-learn                  0.22.2.post1\n",
            "scipy                         1.4.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           2.1.4\n",
            "seaborn                       0.11.1\n",
            "semver                        2.13.0\n",
            "Send2Trash                    1.8.0\n",
            "sentencepiece                 0.1.96\n",
            "seqeval                       1.2.2\n",
            "setuptools                    57.4.0\n",
            "setuptools-git                1.2\n",
            "Shapely                       1.7.1\n",
            "simplegeneric                 0.8.1\n",
            "six                           1.15.0\n",
            "sklearn                       0.0\n",
            "sklearn-pandas                1.8.0\n",
            "smart-open                    5.1.0\n",
            "snowballstemmer               2.1.0\n",
            "sortedcontainers              2.4.0\n",
            "SoundFile                     0.10.3.post1\n",
            "spacy                         2.2.4\n",
            "Sphinx                        1.8.5\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "sphinxcontrib-websupport      1.2.4\n",
            "SQLAlchemy                    1.4.22\n",
            "sqlparse                      0.4.1\n",
            "srsly                         1.0.5\n",
            "statsmodels                   0.10.2\n",
            "sympy                         1.7.1\n",
            "tables                        3.4.4\n",
            "tabulate                      0.8.9\n",
            "tblib                         1.7.0\n",
            "tensorboard                   2.6.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.0\n",
            "tensorflow                    2.6.0\n",
            "tensorflow-addons             0.14.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.6.0\n",
            "tensorflow-gcs-config         2.6.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-metadata           1.2.0\n",
            "tensorflow-model-optimization 0.6.0\n",
            "tensorflow-probability        0.13.0\n",
            "tensorflow-text               2.6.0\n",
            "termcolor                     1.1.0\n",
            "terminado                     0.11.0\n",
            "testpath                      0.5.0\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "tf-models-official            2.6.0\n",
            "tf-slim                       1.1.0\n",
            "Theano-PyMC                   1.1.2\n",
            "thinc                         7.4.0\n",
            "tifffile                      2021.8.30\n",
            "toml                          0.10.2\n",
            "tomli                         1.2.1\n",
            "toolz                         0.11.1\n",
            "torch                         1.9.0+cu102\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.10.0\n",
            "torchvision                   0.10.0+cu102\n",
            "tornado                       5.1.1\n",
            "tqdm                          4.62.0\n",
            "traitlets                     5.0.5\n",
            "tweepy                        3.10.0\n",
            "typeguard                     2.7.1\n",
            "typing-extensions             3.7.4.3\n",
            "tzlocal                       1.5.1\n",
            "uritemplate                   3.0.1\n",
            "urllib3                       1.24.3\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.8.2\n",
            "wcwidth                       0.2.5\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      1.0.1\n",
            "wget                          3.2\n",
            "wheel                         0.37.0\n",
            "widgetsnbextension            3.5.1\n",
            "wordcloud                     1.5.0\n",
            "wrapt                         1.12.1\n",
            "xarray                        0.18.2\n",
            "xgboost                       0.90\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.1.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   0.9.1\n",
            "zict                          2.0.0\n",
            "zipp                          3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrQJCEzP7RYH"
      },
      "source": [
        "import object_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhRsKANibnO4"
      },
      "source": [
        "# Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgtI37vKbpoH"
      },
      "source": [
        "labels = [{'name':'fresh', 'id':1}, {'name':'rotten', 'id':2}]\n",
        "\n",
        "with open(setup.getFiles()['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lyEfFJfgRCZ"
      },
      "source": [
        "# Create Tensorflow Records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JW09lWrgTBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "705f938c-6897-4e75-a793-b5407fbe6a8e"
      },
      "source": [
        "url = 'https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/_downloads/da4babe668a8afb093cc7776d7e630f3/generate_tfrecord.py'\n",
        "src = wget.download(url)\n",
        "dst = setup.getWorkspaces()['PREPROCESSING_PATH']\n",
        "shutil.move(src, dst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tensorflow/scripts/preprocessing/generate_tfrecord.py'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkhzhSrlgiPd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a115ff-ba02-4546-e76d-196e5b89fe88"
      },
      "source": [
        "# Create train data:\n",
        "!python {setup.getFiles()['TFRECORD_SCRIPT']} -x {setup.getWorkspaces()['TRAINING_IMAGES_PATH']} -l {setup.getFiles()['LABELMAP']} -o {os.path.join(setup.getWorkspaces()['ANNOTATIONS_PATH'], 'train.record')}\n",
        "\n",
        "# Create test data:\n",
        "!python {setup.getFiles()['TFRECORD_SCRIPT']} -x {setup.getWorkspaces()['TESTING_IMAGES_PATH']} -l {setup.getFiles()['LABELMAP']} -o {os.path.join(setup.getWorkspaces()['ANNOTATIONS_PATH'], 'train.record')}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-09-02 05:58:16.465342: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/training_demo/annotations/train.record\n",
            "2021-09-02 05:58:19.449855: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/training_demo/annotations/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI0RJtIuzFuZ"
      },
      "source": [
        "# Download Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBKbpGOKoa-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3de85c-0545-4024-fdd7-cdc98819b842"
      },
      "source": [
        "pretrained_mode_file = wget.download(setup.getFiles()['PRETRAINED_MODEL_URL'])\n",
        "shutil.move(pretrained_mode_file, setup.getWorkspaces()['PRETRAINED_MODELS_PATH'])\n",
        "!cd {setup.getWorkspaces()['PRETRAINED_MODELS_PATH']} && tar -zxvf {pretrained_mode_file}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKvUW2BHzKD-"
      },
      "source": [
        "# Make your own copy of pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDR2MKNUuibB"
      },
      "source": [
        "!cp {os.path.join(setup.getWorkspaces()['PRETRAINED_MODELS_PATH'], 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8', 'pipeline.config')} {os.path.join(setup.getWorkspaces()['CHECKPOINT_PATH'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg6mMBUqzvT_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axe3EtdH2QA2"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(setup.getFiles()['PIPELINE_CONFIG'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kbyxlnyGuNq",
        "outputId": "e5dafe47-a4b9-4720-fef4-195182811d06"
      },
      "source": [
        "config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81v__GuKG5yv"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(setup.getFiles()['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv2lPlxyHCCe"
      },
      "source": [
        "pipeline_config.model.ssd.num_classes = len(setup.LABELS)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(setup.getWorkspaces()['PRETRAINED_MODELS_PATH'], 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8', 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= setup.getFiles()['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(setup.getWorkspaces()['ANNOTATIONS_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = setup.getFiles()['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(setup.getWorkspaces()['ANNOTATIONS_PATH'], 'test.record')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d44NPNjrHFsQ"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(setup.getFiles()['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ljtHr0lKUTH"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHTO2UfsH6EJ"
      },
      "source": [
        "TRAINING_SCRIPT = os.path.join(setup.getWorkspaces()['TFOD_API_PATH'], 'models', 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujSKX6LiKXl_",
        "outputId": "aa364ca9-578f-4ea7-fc4e-f546b022f855"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, setup.getWorkspaces()['CHECKPOINT_PATH'],setup.getFiles()['PIPELINE_CONFIG'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mMTq83EIKcr8",
        "outputId": "8480c808-fe8f-4f18-ad5d-62f7aa23e373"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tensorflow/workspace/training_demo/my_ssd_mobnet/pipeline.config'"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj4v6_n_LsSF"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9q_Mb9NLcU8"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1UfGOcGLesu"
      },
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, setup.getWorkspaces()['CHECKPOINT_PATH'], setup.getFiles()['PIPELINE_CONFIG'], setup.getWorkspaces()['CHECKPOINT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nEmQeZTLoqu"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWGJmbqbLu_r"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qjz3E20MQK9"
      },
      "source": [
        "## Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "entHBn2WMXeG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJSqVF2YMem6"
      },
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(setup.getFiles()['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(setup.getWorkspaces()['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uFB7tKnMlWT"
      },
      "source": [
        "## Detect from Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-moarhpeMoNz"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTIc50KJMrGX"
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(setup.getFiles()['LABELMAP'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFWAddlNMtIy"
      },
      "source": [
        "IMAGE_PATH = os.path.join(setup.getWorkspaces()['IMAGES_PATH'], 'test', 'livelong.02533422-940e-11eb-9dbd-5cf3709bbcc6.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNJlBcSYMvUU"
      },
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOAmr6iBM0oB"
      },
      "source": [
        "# Graph Freezing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPr0yV0jM2uu"
      },
      "source": [
        "FREEZE_SCRIPT = os.path.join(setup.getWorkspaces()['TFOD_API_PATH'], 'models', 'research', 'object_detection', 'exporter_main_v2.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEI2BBIFM_c1"
      },
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,setup.getFiles()['PIPELINE_CONFIG'], setup.getWorkspaces()['CHECKPOINT_PATH'], setup.getWorkspaces()['OUTPUT_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDKg8VzUNBuS"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En9bKuXHNCa-"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUnXjBwmNJjB"
      },
      "source": [
        "# Tensorflow Javascript (TFJS) Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w-ltC0qNQoC",
        "outputId": "b78dd947-90fa-4fe5-808c-86b7d293d48c"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-3.9.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-hub<0.13,>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.39.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.17.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.6.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.26.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.34.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow<3,>=2.1.0->tensorflowjs) (3.5.0)\n",
            "Installing collected packages: tensorflowjs\n",
            "Successfully installed tensorflowjs-3.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aklik0O8NTFw"
      },
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(setup.getWorkspaces()['OUTPUT_PATH'], 'saved_model'), setup.getWorkspaces()['TFJS_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Zjz_D_NV8w"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHV8RN80NXpV"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g5hls2-NZ2F"
      },
      "source": [
        "# TF Lite Conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLYDAX-0NZbC"
      },
      "source": [
        "TFLITE_SCRIPT = os.path.join(setup.getWorkspaces()['TFOD_API_PATH'], 'models', 'research', 'object_detection', 'export_tflite_graph_tf2.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cugKlrlNjpd"
      },
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,setup.getFiles()['PIPELINE_CONFIG'], setup.getWorkspaces()['CHECKPOINT_PATH'], setup.getWorkspaces()['TFLITE_PATH'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZfktwcrNlTV"
      },
      "source": [
        "print(command)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-PO3SchNmyC"
      },
      "source": [
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fMWYBkyNqUW"
      },
      "source": [
        "# ZIP and Export Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZULsoTMtNtgK"
      },
      "source": [
        "!tar -czf models.tar.gz {setup.getWorkspaces()['CHECKPOINT_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mi22hyaNuky"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}